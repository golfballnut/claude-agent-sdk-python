# Automation Workspace - LLM Research Pipeline

**START HERE** for Phase 2.5 (LLM API Testing) and Phase 2.6 (Full Automation)

---

## ğŸ¯ Current Phase: 2.5 - LLM API Automation Testing

**Goal:** Test Perplexity/Claude/OpenAI APIs for automated 15,000 course enrichment

**Status:** Ready to build test infrastructure

---

## ğŸ“‚ Directory Structure

```
automation/
â”œâ”€â”€ README.md                    # This file - START HERE
â”œâ”€â”€ CURRENT_PHASE.md             # Single source: "We're in Phase 2.5"
â”œâ”€â”€ api_testing/
â”‚   â”œâ”€â”€ perplexity/              # Perplexity test results
â”‚   â”œâ”€â”€ claude/                  # Claude test results
â”‚   â”œâ”€â”€ openai/                  # OpenAI test results
â”‚   â””â”€â”€ comparison_report.md     # Final API selection
â”œâ”€â”€ edge_functions/
â”‚   â”œâ”€â”€ test-perplexity-research/    # Phase 2.5 test functions
â”‚   â”œâ”€â”€ test-claude-research/
â”‚   â”œâ”€â”€ test-openai-research/
â”‚   â””â”€â”€ batch-llm-research/          # Phase 2.6 production function
â”œâ”€â”€ test_courses/
â”‚   â”œâ”€â”€ tradition_golf_club.json     # 3 test courses for validation
â”‚   â”œâ”€â”€ forest_creek.json
â”‚   â””â”€â”€ hemlock_golf.json
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ v2_research_prompt.md        # Active V2 prompt
â””â”€â”€ docs/
    â”œâ”€â”€ phase_2.5_plan.md            # Complete testing plan
    â”œâ”€â”€ api_references/              # API documentation
    â”‚   â”œâ”€â”€ perplexity_sonar_pro.md
    â”‚   â”œâ”€â”€ claude_sonnet_4.5.md
    â”‚   â”œâ”€â”€ openai_gpt4o.md
    â”‚   â”œâ”€â”€ supabase_edge_functions.md
    â”‚   â””â”€â”€ cost_comparison.md
    â””â”€â”€ monitoring_queries.sql       # Database monitoring
```

---

## ğŸš€ Quick Start for Agents

### Step 1: Read These Files (In Order)
1. `CURRENT_PHASE.md` - What phase we're in
2. `docs/phase_2.5_plan.md` - Complete testing plan
3. `docs/api_references/perplexity_sonar_pro.md` - Primary API docs
4. `../prompts/v2_research_prompt.md` - The actual prompt to use

### Step 2: Execute Phase 2.5.1
- Build 3 test edge functions (Perplexity, Claude, OpenAI)
- Deploy to Supabase
- Configure API keys

### Step 3: Execute Phase 2.5.2
- Test Perplexity on 3 courses
- Validate citation quality (CRITICAL)
- Make GO/NO-GO decision

### Step 4: Fallback Testing (If Needed)
- Test Claude if Perplexity fails
- Test OpenAI if both fail
- Generate comparison report

### Step 5: User Decision
- Present API selection recommendation
- Get budget approval
- Proceed to Phase 2.6 (full automation)

---

## ğŸ“ Context: What We Have Complete

### Infrastructure (100% Built)
- âœ… Render validator service: `https://agent7-water-hazards.onrender.com/validate-and-write`
- âœ… Supabase edge function: `validate-v2-research` (deployed)
- âœ… Database tables: `llm_research_staging`, `golf_courses`, `golf_course_contacts`
- âœ… Test tables: `*_test` for production-safe validation
- âœ… ClickUp integration: Automatic task creation
- âœ… Docker validation: 100% passing

### Proven Quality
- âœ… Manual V2 prompt testing: 100% tier accuracy, 3-4 contacts per course
- âœ… Citation coverage: 100% sourced
- âœ… Validation tested: Course ID 2055 created successfully

---

## ğŸ¯ Success Criteria for Phase 2.5

### Primary Test (Perplexity)
- âœ… **Citations provided** for all claims (URLs, sources) - CRITICAL
- âœ… **Tier accuracy** â‰¥90% vs manual baseline - CRITICAL
- âœ… **Contact count** â‰¥3 per course - HIGH
- âœ… **Email/LinkedIn** for GM or Superintendent - HIGH
- âœ… **Cost** â‰¤$0.01 per course ($75 for 15k) - HIGH

### Fallback Tests (Claude, OpenAI)
- Only run if Perplexity fails CRITICAL checks
- Same success criteria
- Higher cost thresholds ($900, $675 respectively)

---

## ğŸ”— External References

**Parent Project:** `../../` (claude-agent-sdk-python root)
**Production Code:** `../../../../production/golf-enrichment/`
**Legacy V1:** `../../archive/v1_agents/` (reference only)
**Main Docs:** `../../docs/PROGRESS.md` (session history)

---

## âš ï¸ What NOT to Do

- âŒ Don't modify V1 agent files (archived, not used)
- âŒ Don't change database schema (already validated)
- âŒ Don't edit production validator code (working, tested)
- âŒ Don't skip Perplexity test (cheapest option, test first)
- âŒ Don't deploy to production before 3-course pilot

---

**Next Action:** Read `CURRENT_PHASE.md` to confirm current status, then proceed to `docs/phase_2.5_plan.md` for detailed instructions.
