# Claude Code Instructions - Golf Enrichment Team

**Team:** Golf Course Enrichment & Outreach Automation
**Last Updated:** October 30, 2025
**Purpose:** Standards and rules for developing this agent team

---

## ğŸ¯ **Current Workflow Overview (10,000ft View)**

### Apollo Enrichment Pipeline - 80% Automated Success

**What It Does:** Automatically finds and verifies golf course staff contacts with 90%+ confidence emails

**Success Rate:** 80% (4/5 courses get verified contacts)
**Cost:** $0.052/course (74% under $0.20 budget)
**Data Quality:** 100% validated (zero bad contacts allowed)

### 5-Tier Enrichment Cascade

```
1. Apollo.io domain search (20% coverage)
   â†’ Large courses in Apollo's 1.4M+ database
   â†’ Returns: 4 contacts with emails, LinkedIn, tenure
   â†’ Cost: $0.175

2. Hunter.io domain search (20% coverage)
   â†’ Different database coverage than Apollo
   â†’ Returns: Verified emails
   â†’ Cost: $0.049

3. Jina web scraping (60% finds names)
   â†’ Scrapes /contact, /about, /staff pages
   â†’ Returns: Staff names and titles (NO emails)
   â†’ Cost: $0.010

4. Hunter Email Finder (40% enriches names to emails)
   â†’ For each discovered name, find their email
   â†’ Works: john.bellamy@deepspringscc.com (99%)
   â†’ Cost: $0.017/name

5. Email patterns + domain variations (20% final catch)
   â†’ Tests: first@{domain}, first.last@{variations}
   â†’ Variations: onmicrosoft.com, golfclub.com, golf.com
   â†’ Example: rickey@deercroftgolfclub.onmicrosoft.com
   â†’ Verifies: Every pattern before accepting (90%+ only)
   â†’ Cost: Free

Result: 80% automated, 100% validated
```

### Data Validation (CRITICAL)

**Every contact must pass:**
- Email domain matches course domain âœ…
- Not in duplicate person ID blocklist âœ…
- Email confidence â‰¥90% âœ…
- Email verified as deliverable âœ…

**Rejects immediately if any check fails** (prevents corruption)

### Key Files (Start Here)

**Main Agent:** `agents/agent2_apollo_discovery.py` (replaces old Agents 2, 3, 4, 5)
**Orchestrator:** `orchestrator_apollo.py` (5-agent simplified workflow)
**Test Pipeline:** `test_final_pipeline.py` (validates 80% success)
**Documentation:** `testing/SESSION_SUMMARY_OCT30.md` (executive overview)
**Handoff:** `testing/APOLLO_DEBUG_HANDOFF_OCT30.md` (complete reference)

### Deployment Status (Oct 30, 2025)

- Local tests: âœ… 80% validated
- Docker validation: â³ In progress
- Production sync: â¬œ Pending Docker confirmation
- Render deployment: â¬œ Pending sync

### Path to 95% Total Coverage

- **80% automated** (current - deployed)
- **15-20% manual** (sales team LinkedIn research, 10 min/course)
- **= 95-100% total** (hybrid approach)

**Why hybrid:** Automation ceiling reached at 80% (very small courses lack public data)

---

## ğŸš¨ **CRITICAL RULES (Follow These!)**

### **Rule #1: Documentation Limit - MAX 5 Files at Team Root** â­

**ALLOWED at `teams/golf-enrichment/` root:**
1. âœ… START_HERE.md (entry point - REQUIRED)
2. âœ… README.md (team overview - REQUIRED)
3. âœ… CLAUDE.md (this file - team rules)
4. âœ… CHANGELOG.md (version history - optional)
5. âœ… [ONE flex spot for urgent notes]

**EVERYTHING ELSE goes in docs/**:
- Implementation specs â†’ `docs/1_IMPLEMENTATION/`
- Operations guides â†’ `docs/2_OPERATIONS/`
- Background context â†’ `docs/3_REFERENCE/`

**Before creating new .md file, ask:**
1. Can this go in START_HERE.md? (if < 500 words, YES)
2. Can existing doc be updated instead?
3. Does this belong in docs/ subfolder?
4. Is this temporary? (use code comments or ClickUp task instead)

**If you create 6th .md file at root â†’ STOP and consolidate!**

---

### **Rule #2: Update START_HERE.md, Don't Create New Status Files**

âŒ **DON'T CREATE:**
- PROGRESS.md, STATUS.md, UPDATES.md
- NEXT_STEPS.md, TODO.md
- NOTES_[DATE].md

âœ… **INSTEAD:**
- Update START_HERE.md "What's Next" section
- Update START_HERE.md "Current Status"
- Add dated section to START_HERE.md if needed

**Why:** One entry point is better than 5 status files

---

### **Rule #3: Cost Discipline - Every Agent < $0.02**

**Cost Targets:**
- Agent 1: < $0.02
- Agent 2: < $0.02
- Agents 3-7: < $0.02 each
- **Total per course: < $0.20** (with 4 contacts max)

**Test costs before deploying:**
```bash
pytest teams/golf-enrichment/tests/test_agent1.py -v
# Check output for cost data
```

**If agent exceeds budget:**
1. Optimize queries (reduce Perplexity calls)
2. Use cheaper model if possible
3. Cache results
4. Document in COST_OPTIMIZATION.md

**Track in:** `docs/2_OPERATIONS/COST_OPTIMIZATION.md`

---

### **Rule #4: Never Edit production/ Directly**

âŒ **NEVER:**
```bash
# DON'T edit files in production/golf-enrichment/
vim production/golf-enrichment/agents/agent1.py  # NO!
```

âœ… **INSTEAD:**
```bash
# Edit in teams folder
vim teams/golf-enrichment/agents/agent1.py

# Sync to production
python production/scripts/sync_to_production.py golf-enrichment

# Deploy
cd production/golf-enrichment
git add . && git commit -m "Update agent1" && git push
```

**Why:** Production is isolated, synced from development

---

### **Rule #5: Test Locally Before Deploying**

**Required testing sequence:**
```bash
# 1. Unit test
pytest teams/golf-enrichment/tests/test_agent1.py

# 2. Integration test
pytest teams/golf-enrichment/tests/test_orchestrator.py

# 3. Docker test
cd teams/golf-enrichment
docker-compose up --build

# 4. Production mirror test
docker-compose -f docker-compose.production-mirror.yml up

# 5. Only then: Sync and deploy
python ../../production/scripts/sync_to_production.py golf-enrichment
```

**Never skip steps 1-4!**

---

## ğŸ“ **Project Structure (Where Things Go)**

### **Team Folder Organization:**

```
teams/golf-enrichment/
â”œâ”€â”€ START_HERE.md â­ Entry point (update this for status)
â”œâ”€â”€ README.md (team overview, rarely changes)
â”œâ”€â”€ CLAUDE.md (this file - team rules)
â”œâ”€â”€ CHANGELOG.md (version history - optional)
â”‚
â”œâ”€â”€ agents/ (all agent implementations)
â”‚   â”œâ”€â”€ agent1_url_finder.py
â”‚   â”œâ”€â”€ agent2_data_extractor.py
â”‚   â””â”€â”€ ... (8 agents total)
â”‚
â”œâ”€â”€ orchestrator.py (workflow coordinator)
â”‚
â”œâ”€â”€ tests/ (all test files)
â”‚   â”œâ”€â”€ test_agent1.py
â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â””â”€â”€ test_data/
â”‚
â”œâ”€â”€ migrations/ (database migrations)
â”‚   â”œâ”€â”€ 004_agent_integration_fields.sql
â”‚   â””â”€â”€ 005_outreach_tables.sql
â”‚
â”œâ”€â”€ docker-compose.yml (local testing)
â”œâ”€â”€ docker-compose.production-mirror.yml (staging)
â”‚
â””â”€â”€ docs/ (detailed documentation - organized!)
    â”œâ”€â”€ 1_IMPLEMENTATION/ (what to build next)
    â”‚   â”œâ”€â”€ CLICKUP_ARCHITECTURE.md
    â”‚   â”œâ”€â”€ EDGE_FUNCTIONS.md
    â”‚   â””â”€â”€ OUTREACH_TASK_TEMPLATE.md
    â”œâ”€â”€ 2_OPERATIONS/ (how to operate)
    â”‚   â”œâ”€â”€ RELIABILITY_PLAYBOOK.md
    â”‚   â”œâ”€â”€ EDGE_CASE_PLAYBOOK.md
    â”‚   â””â”€â”€ COST_OPTIMIZATION.md
    â””â”€â”€ 3_REFERENCE/ (background info)
        â”œâ”€â”€ goal.md
        â”œâ”€â”€ outreachgoalsv1_101725.md
        â””â”€â”€ business_opportunities.md
```

**If you add a file not shown above â†’ reconsider!**

---

## ğŸ¯ **Development Workflow**

### **To Add New Agent:**

1. Create: `agents/agent9_new_capability.py`
2. Create: `tests/test_agent9.py`
3. Test: `pytest tests/test_agent9.py`
4. Update: `orchestrator.py` (add agent9 to workflow)
5. Update: `START_HERE.md` (note agent9 added)
6. Sync: `python ../../production/scripts/sync_to_production.py golf-enrichment`
7. Deploy: From production folder, git push

### **To Update Existing Agent:**

1. Edit: `agents/agent6_course_intelligence.py`
2. Test: `pytest tests/test_agent6.py`
3. Update: `docs/2_OPERATIONS/COST_OPTIMIZATION.md` if cost changed
4. Update: `START_HERE.md` with changes
5. Sync and deploy

### **To Add Documentation:**

**Ask first: Where does this belong?**

**Implementation detail** (migration, field spec, template)?
â†’ `docs/1_IMPLEMENTATION/FILENAME.md`

**Operations guide** (monitoring, errors, costs)?
â†’ `docs/2_OPERATIONS/FILENAME.md`

**Background context** (business goals, roadmap)?
â†’ `docs/3_REFERENCE/FILENAME.md`

**Quick status update**?
â†’ Update `START_HERE.md` (don't create new file!)

**Temporary note**?
â†’ Use code comment or ClickUp task (not .md file!)

---

## ğŸ“Š **Quality Standards**

### **Agent Quality Checklist:**

Every agent must have:
- [ ] Docstring with purpose, inputs, outputs
- [ ] Error handling (try/catch with meaningful errors)
- [ ] Cost tracking (log every API call cost)
- [ ] Type hints (use claude_agent_sdk types)
- [ ] Test file with 3+ test cases
- [ ] Cost < $0.02 target

### **Documentation Quality:**

Every implementation doc must have:
- [ ] Purpose statement
- [ ] Code examples
- [ ] Testing instructions
- [ ] Edge case notes
- [ ] Last updated date

### **Testing Requirements:**

Before deployment:
- [ ] Unit tests pass (all agents)
- [ ] Integration test passes (orchestrator)
- [ ] Cost test passes (< $0.20/course)
- [ ] Docker build succeeds
- [ ] Production mirror test works

---

## ğŸ”§ **Common Tasks**

### **Update Agent Costs:**
```bash
# After optimizing agent
pytest tests/test_agent6.py

# Update cost doc
vim docs/2_OPERATIONS/COST_OPTIMIZATION.md
# Update: Agent 6 cost from $0.036 â†’ $0.024

# Update START_HERE
vim START_HERE.md
# Update: "Cost per course: $0.19 â†’ $0.17"
```

### **Add ClickUp Field:**
```bash
# 1. Add field in ClickUp UI
# 2. Get field ID from ClickUp API
# 3. Update config
vim config/clickup-field-mapping.json
# Add: {"new_field": "field_id_here"}

# 4. Update edge function
vim docs/1_IMPLEMENTATION/EDGE_FUNCTIONS.md
# Add field to create-outreach-task function

# 5. Document
vim docs/1_IMPLEMENTATION/CLICKUP_ARCHITECTURE.md
# Add to field list with purpose
```

### **Handle New Edge Case:**
```bash
# Discovered: "Contact on vacation auto-reply"

# 1. Document
vim docs/2_OPERATIONS/EDGE_CASE_PLAYBOOK.md
# Add: Edge Case #11: Vacation Auto-Reply

# 2. Update code if needed
vim agents/agent3_contact_enricher.py
# Add: Detection for vacation auto-reply

# 3. Update START_HERE
vim START_HERE.md
# Note: "Added vacation auto-reply handling"
```

---

## ğŸ’° **Cost Monitoring (Weekly)**

**Check actual costs:**
```sql
-- In Supabase
SELECT
  DATE(enrichment_requested_at) as week,
  COUNT(*) as courses,
  AVG(agent_cost_usd) as avg_cost,
  SUM(agent_cost_usd) as total_cost
FROM golf_courses
WHERE enrichment_completed_at > NOW() - INTERVAL '7 days'
GROUP BY DATE(enrichment_requested_at);
```

**If avg_cost > $0.25:**
1. Review: `docs/2_OPERATIONS/COST_OPTIMIZATION.md`
2. Implement: Contact filtering (limit to 4)
3. Implement: Agent 6 query consolidation
4. Test: Verify cost reduction
5. Update: START_HERE.md with new costs

---

## ğŸš€ **Deployment Checklist**

**Before every production deploy:**
- [ ] All tests pass locally
- [ ] Cost validated (< $0.20/course)
- [ ] Docker build succeeds
- [ ] START_HERE.md updated with changes
- [ ] Sync script run: `python production/scripts/sync_to_production.py golf-enrichment`
- [ ] Git commit from production folder
- [ ] Monitor Render deployment logs
- [ ] Test production endpoint: `curl https://agent7-water-hazards.onrender.com/health`

---

## ğŸ“š **Documentation Maintenance**

### **Weekly:**
- Update START_HERE.md if status changed
- Review docs/ for outdated info
- Check if > 5 files at root (consolidate if so)

### **Monthly:**
- Update COST_OPTIMIZATION.md with actual costs
- Review EDGE_CASE_PLAYBOOK for new scenarios
- Update RELIABILITY_PLAYBOOK with learned issues

### **Quarterly:**
- Full docs review
- Archive outdated reference docs
- Update README.md if team mission changed

---

## ğŸ¯ **Success Metrics**

**This team is successful if:**
- âœ… Cost < $0.20 per course (with 4 contacts)
- âœ… Success rate > 95% (enrichment completes)
- âœ… Documentation stays organized (< 5 root files)
- âœ… New contributors can start in < 30 minutes
- âœ… No production incidents from poor testing

**Track in:** START_HERE.md "Success Metrics" section

---

## ğŸš« **Anti-Patterns (DON'T DO THIS)**

### **Documentation Anti-Patterns:**
âŒ Creating PROGRESS.md at root (update START_HERE instead)
âŒ Creating dated notes files (NOTES_OCT_18.md)
âŒ Duplicating files (root + team folder)
âŒ Mixing code and docs (orchestrator.py in docs/)
âŒ Creating > 5 files at root without consolidating

### **Code Anti-Patterns:**
âŒ Editing production/ directly
âŒ Skipping tests before deploy
âŒ Committing .env files
âŒ Creating agents without cost tracking
âŒ Deploying without docker-compose test

### **Cost Anti-Patterns:**
âŒ Enriching all 7+ contacts (filter to 4!)
âŒ Not tracking cost per agent
âŒ Deploying optimizations without testing
âŒ Ignoring cost alerts (> $0.25/course)

---

## ğŸ“– **Quick Reference**

### **Where is...?**

**Entry point for new contributors:**
â†’ `START_HERE.md`

**What to build next:**
â†’ `docs/1_IMPLEMENTATION/`

**How to handle errors:**
â†’ `docs/2_OPERATIONS/RELIABILITY_PLAYBOOK.md`

**Why we built this:**
â†’ `docs/3_REFERENCE/goal.md`

**Current production URL:**
â†’ https://agent7-water-hazards.onrender.com

**Testing:**
â†’ `tests/` folder

**Database migrations:**
â†’ `migrations/` folder

---

## ğŸ”„ **This File**

**When to update CLAUDE.md:**
- New critical rule discovered
- Common mistake pattern identified
- Development workflow changes
- New anti-pattern to avoid

**Who maintains:** Team lead + contributors
**Review frequency:** When onboarding new developers

---

## ğŸ“ **Questions?**

- **Team questions:** Read START_HERE.md first
- **SDK questions:** See root README.md
- **Project structure:** See root PROJECT_STRUCTURE.md

---

**Remember: Keep it simple, keep it organized, keep costs low!** ğŸ¯
