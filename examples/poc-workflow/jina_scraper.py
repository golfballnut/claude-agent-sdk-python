#!/usr/bin/env python3
"""
POC: Web Scraping with Jina MCP Server

This demonstrates:
1. Using external MCP server (Jina)
2. Web scraping real websites
3. Extracting specific information
4. Agent-based workflow for data extraction
"""

import anyio
import os
from claude_agent_sdk import (
    query,
    ClaudeAgentOptions,
    AgentDefinition,
    AssistantMessage,
    ResultMessage,
    TextBlock,
    SystemMessage,
)


async def main():
    print("üåê Starting Web Scraping POC with Jina MCP")
    print("=" * 70)

    # Check for API key
    jina_api_key = os.environ.get("JINA_API_KEY")
    if not jina_api_key:
        print("‚ùå ERROR: JINA_API_KEY environment variable not set!")
        print("\nüìù To fix this:")
        print("   1. Get a free API key from: https://jina.ai/?sui=apikey")
        print("   2. Set the environment variable:")
        print("      export JINA_API_KEY='your_api_key_here'")
        print("   3. Run this script again\n")
        return

    print(f"‚úÖ Jina API Key found: {jina_api_key[:10]}...")
    print()

    # Configure Jina MCP server with API key
    # KEY DIFFERENCE FROM CLI: SDK needs 'env' field for API keys
    mcp_servers = {
        "jina": {
            "command": "npx",
            "args": ["-y", "@jina-ai/mcp-server-jina"],
            "env": {
                "JINA_API_KEY": jina_api_key
            }
        }
    }

    # Define scraper agent
    options = ClaudeAgentOptions(
        agents={
            "scraper": AgentDefinition(
                description="Scrapes websites and extracts specific information from web pages",
                prompt=(
                    "You are a web scraping specialist. Use the Jina MCP tools to:\n"
                    "1. Fetch web page content\n"
                    "2. Parse and analyze the content\n"
                    "3. Extract specific information requested\n"
                    "4. Return results in a clear, structured format\n\n"
                    "Be thorough in your search and provide the exact information requested."
                ),
                tools=["mcp__jina__fetch", "mcp__jina__search"],
                model="sonnet"
            )
        },
        mcp_servers=mcp_servers,
        allowed_tools=["mcp__jina__fetch", "mcp__jina__search"],
        permission_mode="acceptEdits"
    )

    # The scraping task
    target_url = "https://vsga.org/member-clubs"
    course_name = "Raspberry Falls Golf & Hunt Club"

    workflow_prompt = f"""
    Please use the scraper agent to complete this task:

    1. Scrape the webpage: {target_url}
    2. Find the course named: "{course_name}"
    3. Extract the URL link for that course
    4. Return the complete URL

    The expected URL format should be something like:
    https://vsga.org/courselisting/[ID]?hsLang=en

    Please provide the exact URL you find.
    """

    print("\nüìù Task:")
    print(f"   URL: {target_url}")
    print(f"   Looking for: {course_name}")
    print("\n" + "=" * 70)
    print("ü§ñ Executing Scraper Agent...\n")

    found_url = None

    # Execute the workflow
    try:
        async for message in query(prompt=workflow_prompt, options=options):
            if isinstance(message, AssistantMessage):
                for block in message.content:
                    if isinstance(block, TextBlock):
                        print(f"üí¨ Claude: {block.text}")
                        print()

                        # Try to extract URL from response
                        if "vsga.org/courselisting" in block.text:
                            # Simple extraction
                            import re
                            urls = re.findall(r'https://vsga\.org/courselisting/\d+\?hsLang=en', block.text)
                            if urls:
                                found_url = urls[0]

            elif isinstance(message, SystemMessage):
                print(f"üîß System: {message.subtype}")
                if message.data:
                    print(f"   Data: {message.data}")
                print()

            elif isinstance(message, ResultMessage):
                print("=" * 70)
                print("‚úÖ Scraping Complete!")
                print(f"‚è±Ô∏è  Duration: {message.duration_ms / 1000:.2f}s")
                print(f"üîÑ Turns: {message.num_turns}")
                if message.total_cost_usd:
                    print(f"üí∞ Cost: ${message.total_cost_usd:.4f}")

                if found_url:
                    print("\n" + "=" * 70)
                    print("üéØ RESULT FOUND:")
                    print(f"   {found_url}")
                    print("=" * 70)
                else:
                    print("\n‚ö†Ô∏è  Could not extract URL from response")

    except Exception as e:
        print(f"\n‚ùå Error occurred: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    anyio.run(main)
